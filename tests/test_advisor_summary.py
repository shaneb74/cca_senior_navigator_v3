"""
Test script for Advisor Summary LLM Engine

This script tests the advisor summary generation without requiring Streamlit session state.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai.advisor_summary_templates import EXAMPLE_CONTEXT, EXAMPLE_OUTPUTS
from ai.advisor_summary_engine import AdvisorSummaryEngine


def test_template_output():
    """Test the advisor summary templates with example data."""
    print("=== Advisor Summary LLM Templates ===\n")
    
    print("This system generates four narrative 'drawers' for advisor dashboards:")
    print("1. About the Person - Introduction and living situation")
    print("2. Housing Preferences - Preferred care setting and timeline")  
    print("3. Medical & Care Information - Care needs and coordination")
    print("4. Financial Overview - Budget and funding timeline\n")
    
    print("Target Audience: Internal business and advisor stakeholders")
    print("Tone: Warm, empathetic, factual - suitable for internal reports")
    print("Length: 80-120 words per drawer\n")
    
    print("=" * 60)
    print("EXAMPLE OUTPUTS (Static Templates)")
    print("=" * 60 + "\n")
    
    for drawer_name, example in EXAMPLE_OUTPUTS.items():
        print(f"## {drawer_name.replace('_', ' ').title()}")
        print(f"Length: {len(example.split())} words")
        print(example)
        print("\n" + "-"*50 + "\n")
    
    print("=" * 60)
    print("CONTEXT DATA USED")
    print("=" * 60 + "\n")
    
    print("Example data that would be extracted from GCP, Cost Planner, and session state:")
    print(f"- Person: {EXAMPLE_CONTEXT.person_a_name}, {EXAMPLE_CONTEXT.person_a_age_range}")
    print(f"- Location: ZIP {EXAMPLE_CONTEXT.geo_zip}")
    print(f"- Recommended Care: {EXAMPLE_CONTEXT.recommended_tier}")
    print(f"- Room Type: {EXAMPLE_CONTEXT.room_type}")
    print(f"- Move Timeline: {EXAMPLE_CONTEXT.move_timeline}")
    print(f"- Care Flags: {', '.join(EXAMPLE_CONTEXT.care_flags)}")
    print(f"- Monthly Cost: ${EXAMPLE_CONTEXT.monthly_cost:,.0f}")
    print(f"- Years Funded: {EXAMPLE_CONTEXT.years_funded:.1f}")
    print(f"- VA Benefits Eligible: {EXAMPLE_CONTEXT.va_benefits_eligible}")
    print(f"- Support Network Low: {EXAMPLE_CONTEXT.support_network_low}")
    print(f"- Home Carry: {EXAMPLE_CONTEXT.home_carry}")
    
    print("\n" + "=" * 60)
    print("INTEGRATION NOTES")
    print("=" * 60 + "\n")
    
    print("ðŸ”Œ INTEGRATION WITH EXISTING SYSTEM:")
    print("- Uses existing LLMClient from ai/llm_client.py")
    print("- Extracts data from Streamlit session state automatically")
    print("- Integrates with GCP care_recommendation data")
    print("- Uses Cost Planner financial_assessment_complete data")
    print("- Leverages existing flag_manager_flags system")
    
    print("\nðŸ“Š DATA SOURCES:")
    print("- Profile: person_a_name, age_range, relationship_type, geo.zip")
    print("- GCP: recommended_tier, care_flags, move_timeline, room_type") 
    print("- Cost Planner: monthly_cost, assets, income, years_funded")
    print("- Flags: support_network_low, va_benefits_eligible, etc.")
    
    print("\nðŸŽ¯ USAGE:")
    print("from ai.advisor_summary_engine import AdvisorSummaryEngine")
    print("drawers = AdvisorSummaryEngine.generate_all_drawers()")
    print("# Returns dict with 'about_person', 'housing_preferences', etc.")
    
    print("\nâœ… READY FOR PRODUCTION:")
    print("- Graceful fallback to static content if LLM fails")
    print("- Handles missing or incomplete session data")
    print("- Uses existing GPT-4o-mini via LLMClient")
    print("- Proper error handling and logging")


if __name__ == "__main__":
    test_template_output()